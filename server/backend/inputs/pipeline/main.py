# coding=utf-8

"""
NFX-Vault Pipeline Server - Kafka Consumer æœåŠ¡

ç›‘å¬ Kafka äº‹ä»¶å¹¶å¤„ç†ï¼ˆoperation.refreshï¼‰
"""
import os
import signal
import logging
import time

# åœ¨ Docker ä¸­ï¼Œå·¥ä½œç›®å½•æ˜¯ backend æ ¹ç›®å½•ï¼Œæ‰€ä»¥å¯ä»¥ç›´æ¥å¯¼å…¥
from modules.configs import load_config, DatabaseConfig, CertConfig, init_connections, cleanup_connections

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨å±€è¿è¡ŒçŠ¶æ€
running = True


def signal_handler(sig, frame):
    """ä¿¡å·å¤„ç†å™¨ï¼ˆä¼˜é›…å…³é—­ï¼‰"""
    global running
    logger.info("\nğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
    running = False


def run_pipeline_server():
    """Pipeline æœåŠ¡å™¨æ¨¡å¼ï¼šæŒç»­è¿è¡Œï¼Œç›‘å¬ Kafka äº‹ä»¶"""
    global running
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
    
    # åŠ è½½é…ç½®
    cert_config, db_config = load_config()
    
    logger.info("=" * 60)
    logger.info("  NFX-Vault Pipeline Server - Kafka Consumer Service")
    logger.info("=" * 60)
    logger.info("ğŸš€ å¯åŠ¨ Pipeline æœåŠ¡å™¨æ¨¡å¼ï¼ˆKafka äº‹ä»¶ç›‘å¬ï¼‰")
    
    # åˆå§‹åŒ–è¿æ¥ï¼ˆMySQL, Redis, Kafkaï¼‰å’Œ Controllers
    connections = init_connections(db_config=db_config, cert_config=cert_config)
    
    # å¯åŠ¨ Kafka ç›‘å¬çº¿ç¨‹ï¼ˆcontroller å·²ç»é€šè¿‡ event_router æ³¨å†Œåˆ° kafka_consumerï¼‰
    kafka_consumer_thread = None
    if connections.kafka_consumer:
        from resources.kafka import KafkaConsumerThread
        if connections.kafka_consumer.start():
            kafka_consumer_thread = KafkaConsumerThread(connections.kafka_consumer)
            kafka_consumer_thread.start()
            logger.info("âœ… Kafka Consumer ç›‘å¬çº¿ç¨‹å·²å¯åŠ¨ï¼ˆcontroller å·²æ³¨å†Œï¼‰")
        else:
            logger.error("âŒ Kafka Consumer å¯åŠ¨å¤±è´¥")
    
    # ä¸»å¾ªç¯ï¼šæŒç»­è¿è¡Œï¼ˆKafka ç›‘å¬åœ¨åå°çº¿ç¨‹è¿è¡Œï¼‰
    logger.info("ğŸ”„ Pipeline æœåŠ¡å™¨æ­£åœ¨è¿è¡Œï¼Œç­‰å¾… Kafka äº‹ä»¶...")
    
    try:
        while running:
            # æ£€æŸ¥ Kafka Consumer çº¿ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
            if kafka_consumer_thread and not kafka_consumer_thread.is_alive():
                logger.error("âŒ Kafka Consumer çº¿ç¨‹æ„å¤–é€€å‡º")
                break
            
            # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
            time.sleep(1)
            
    except KeyboardInterrupt:
        logger.info("\nğŸ›‘ æ”¶åˆ°é”®ç›˜ä¸­æ–­ä¿¡å·")
    except Exception as e:
        logger.error(f"âŒ ä¸»å¾ªç¯å‡ºé”™: {e}", exc_info=True)
    
    # åœæ­¢ Kafka Consumer çº¿ç¨‹
    if kafka_consumer_thread and connections.kafka_consumer:
        logger.info("ğŸ›‘ æ­£åœ¨åœæ­¢ Kafka Consumer çº¿ç¨‹...")
        connections.kafka_consumer.stop()
        kafka_consumer_thread.join(timeout=5)
        if kafka_consumer_thread.is_alive():
            logger.warning("âš ï¸  Kafka Consumer çº¿ç¨‹æœªåœ¨ 5 ç§’å†…åœæ­¢")
        else:
            logger.info("âœ… Kafka Consumer çº¿ç¨‹å·²åœæ­¢")
    
    # æ¸…ç†è¿æ¥
    cleanup_connections(connections)
    logger.info("ğŸ‘‹ Pipeline æœåŠ¡å™¨å·²åœæ­¢")


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¯åŠ¨ Pipeline Serverï¼ˆKafka Consumer æ¨¡å¼ï¼‰")
    logger.info("ğŸ“Œ æ³¨æ„ï¼šæ­¤æ¨¡å¼ä¾èµ– Kafkaï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®é…ç½®")
    
    try:
        run_pipeline_server()
    except FileNotFoundError as e:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶é”™è¯¯: {e}")
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºè¿è¡Œé”™è¯¯: {e}", exc_info=True)
        raise


if __name__ == "__main__":
    main()

