# coding=utf-8

"""
Kafka Consumer å®¢æˆ·ç«¯

è´Ÿè´£ç›‘å¬ Kafka topics å¹¶å¤„ç†äº‹ä»¶
"""
import json
import logging
import threading
from typing import Optional, Callable, Dict, Any
from datetime import datetime

try:
    from kafka import KafkaConsumer
    from kafka.errors import KafkaError
    KAFKA_AVAILABLE = True
except ImportError as e:
    KAFKA_AVAILABLE = False
    logging.warning(f"kafka-python æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥ï¼ŒKafka åŠŸèƒ½å°†ä¸å¯ç”¨: {e}")
except Exception as e:
    KAFKA_AVAILABLE = False
    logging.warning(f"kafka-python å¯¼å…¥æ—¶å‘ç”Ÿé”™è¯¯ï¼ŒKafka åŠŸèƒ½å°†ä¸å¯ç”¨: {e}")


class KafkaEventConsumer:
    """Kafka äº‹ä»¶æ¶ˆè´¹è€…"""
    
    # Event Type Header Keyï¼ˆå‚è€ƒ Sjgz-Backendï¼‰
    EVENT_TYPE_HEADER_KEY = "event_type"
    
    def __init__(
        self,
        bootstrap_servers: str = "Resources-Kafka:9092",
        topic: str = "trendradar.crawl_server",
        group_id: str = "trendradar-crawl-server",
        enable_auto_commit: bool = True,
    ):
        """
        åˆå§‹åŒ– Kafka æ¶ˆè´¹è€…
        
        Args:
            bootstrap_servers: Kafka æœåŠ¡å™¨åœ°å€
            topic: è¦ç›‘å¬çš„ topic åç§°
            group_id: æ¶ˆè´¹è€…ç»„ ID
            enable_auto_commit: æ˜¯å¦è‡ªåŠ¨æäº¤ offset
        """
        self.bootstrap_servers = bootstrap_servers
        self.topic = topic
        self.group_id = group_id
        self.enable_auto_commit = enable_auto_commit
        self.consumer: Optional[KafkaConsumer] = None
        self.logger = logging.getLogger(__name__)
        self.running = False
        self.handlers: Dict[str, Callable[[Dict[str, Any]], None]] = {}
        
        # ç¦ç”¨ kafka-python åº“çš„è¯¦ç»†æ—¥å¿—
        if KAFKA_AVAILABLE:
            logging.getLogger('kafka').setLevel(logging.WARNING)
            logging.getLogger('kafka.conn').setLevel(logging.WARNING)
            logging.getLogger('kafka.coordinator').setLevel(logging.WARNING)
            logging.getLogger('kafka.consumer').setLevel(logging.WARNING)
            logging.getLogger('kafka.cluster').setLevel(logging.WARNING)
        
    def register_handler(self, event_type: str, handler: Callable[[Dict[str, Any]], None]):
        """
        æ³¨å†Œäº‹ä»¶å¤„ç†å™¨
        
        Args:
            event_type: äº‹ä»¶ç±»å‹ï¼ˆå¦‚ "operation.crawl"ï¼‰
            handler: å¤„ç†å‡½æ•°ï¼Œæ¥æ”¶äº‹ä»¶æ•°æ®å­—å…¸
        """
        self.handlers[event_type] = handler
        self.logger.debug(f"âœ… æ³¨å†Œäº‹ä»¶å¤„ç†å™¨: {event_type}")
    
    def start(self):
        """å¯åŠ¨æ¶ˆè´¹è€…"""
        if not KAFKA_AVAILABLE:
            self.logger.error("âŒ kafka-python æœªå®‰è£…ï¼Œæ— æ³•å¯åŠ¨æ¶ˆè´¹è€…")
            return False
        
        try:
            self.consumer = KafkaConsumer(
                self.topic,
                bootstrap_servers=self.bootstrap_servers,
                group_id=self.group_id,
                value_deserializer=lambda m: json.loads(m.decode('utf-8')),
                enable_auto_commit=self.enable_auto_commit,
                auto_offset_reset='latest',  # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹
                consumer_timeout_ms=1000,  # 1ç§’è¶…æ—¶ï¼Œç”¨äºä¼˜é›…é€€å‡º
            )
            self.running = True
            self.logger.info(f"âœ… Kafka è¿æ¥æˆåŠŸ: topic={self.topic}, group_id={self.group_id}")
            return True
        except Exception as e:
            self.logger.error(f"âŒ Kafka æ¶ˆè´¹è€…å¯åŠ¨å¤±è´¥: {e}")
            return False
    
    def consume_loop(self):
        """æ¶ˆè´¹å¾ªç¯ï¼ˆåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­è¿è¡Œï¼‰"""
        if not self.consumer:
            self.logger.error("âŒ æ¶ˆè´¹è€…æœªåˆå§‹åŒ–ï¼Œæ— æ³•å¯åŠ¨æ¶ˆè´¹å¾ªç¯")
            return
        
        self.logger.debug(f"ğŸ”„ å¼€å§‹ç›‘å¬ Kafka topic: {self.topic}")
        
        while self.running:
            try:
                # è·å–æ¶ˆæ¯ï¼ˆå¸¦è¶…æ—¶ï¼Œä¾¿äºæ£€æŸ¥ running çŠ¶æ€ï¼‰
                message_pack = self.consumer.poll(timeout_ms=1000)
                
                if not message_pack:
                    continue
                
                for topic_partition, messages in message_pack.items():
                    for message in messages:
                        try:
                            self._handle_message(message)
                        except Exception as e:
                            self.logger.error(f"âŒ å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}", exc_info=True)
                            
            except Exception as e:
                if self.running:
                    self.logger.error(f"âŒ æ¶ˆè´¹æ¶ˆæ¯æ—¶å‡ºé”™: {e}", exc_info=True)
                break
        
        self.logger.debug("ğŸ›‘ Kafka æ¶ˆè´¹è€…å¾ªç¯å·²åœæ­¢")
    
    def _handle_message(self, message):
        """å¤„ç†å•æ¡æ¶ˆæ¯"""
        # ä» headers ä¸­è·å– event_typeï¼ˆå‚è€ƒ Sjgz-Backendï¼‰
        event_type = None
        
        # kafka-python çš„ headers æ ¼å¼: [(key_str, value_bytes), ...]
        # æ³¨æ„: å®é™…æ¥æ”¶æ—¶ key å¯èƒ½æ˜¯ str æˆ– bytesï¼Œvalue æ˜¯ bytes
        if message.headers:
            for header_key, header_value in message.headers:
                try:
                    key_str = header_key.decode('utf-8') if isinstance(header_key, bytes) else header_key
                    if key_str == self.EVENT_TYPE_HEADER_KEY:
                        event_type = header_value.decode('utf-8') if isinstance(header_value, bytes) else header_value
                        break
                except (UnicodeDecodeError, AttributeError):
                    continue
        
        if not event_type:
            self.logger.warning(f"âš ï¸  æ¶ˆæ¯ç¼ºå°‘ event_type header: topic={message.topic}, offset={message.offset}")
            return
        
        # è·å–äº‹ä»¶æ•°æ®
        event_data = message.value if message.value else {}
        
        # æŸ¥æ‰¾å¹¶è°ƒç”¨å¤„ç†å™¨
        handler = self.handlers.get(event_type)
        if handler:
            self.logger.debug(f"ğŸ“¨ æ”¶åˆ°äº‹ä»¶: {event_type}, offset={message.offset}")
            try:
                handler(event_data)
            except Exception as e:
                self.logger.error(f"âŒ äº‹ä»¶å¤„ç†å™¨æ‰§è¡Œå¤±è´¥: event_type={event_type}, error={e}", exc_info=True)
        else:
            self.logger.warning(f"âš ï¸  æœªæ³¨å†Œçš„äº‹ä»¶ç±»å‹: {event_type}, offset={message.offset}")
    
    def stop(self):
        """åœæ­¢æ¶ˆè´¹è€…"""
        self.logger.debug("ğŸ›‘ æ­£åœ¨åœæ­¢ Kafka æ¶ˆè´¹è€…...")
        self.running = False
        
        if self.consumer:
            try:
                self.consumer.close()
                self.logger.debug("âœ… Kafka æ¶ˆè´¹è€…å·²å…³é—­")
            except Exception as e:
                self.logger.error(f"âŒ å…³é—­æ¶ˆè´¹è€…æ—¶å‡ºé”™: {e}")


class KafkaConsumerThread(threading.Thread):
    """Kafka æ¶ˆè´¹è€…çº¿ç¨‹åŒ…è£…å™¨"""
    
    def __init__(self, consumer: KafkaEventConsumer):
        super().__init__(daemon=True, name="KafkaConsumer")
        self.consumer = consumer
    
    def run(self):
        """è¿è¡Œæ¶ˆè´¹è€…å¾ªç¯"""
        self.consumer.consume_loop()

